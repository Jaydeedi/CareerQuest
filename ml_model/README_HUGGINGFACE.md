
# CareerQuest ML API - Hugging Face Deployment

This is the ML prediction service for CareerQuest, deployed on Hugging Face Spaces.

## Deployment Steps

1. Create a new Space on Hugging Face:
   - Go to https://huggingface.co/spaces
   - Click "Create new Space"
   - Choose "Gradio" or "Docker" SDK
   - Name it: `careerquest-ml-api`

2. Upload these files to your Space:
   ```
   ml_model/
   â”œâ”€â”€ app.py
   â”œâ”€â”€ prediction_service.py
   â”œâ”€â”€ requirements.txt
   â”œâ”€â”€ saved_models/
   â”‚   â”œâ”€â”€ *.pkl files
   â”‚   â””â”€â”€ *.json files
   â””â”€â”€ README.md
   ```

3. The service will automatically start and show logs like:
   ```
   ===== Application Startup at 2025-01-XX XX:XX:XX =====
   
   ğŸš€ Starting CareerQuest ML API (HuggingFace Spaces)...
   
   âœ… Models loaded successfully!
      Features: 12 features
      âœ“ Question Classifier
      âœ“ Difficulty Predictor
      âœ“ Career Recommender (Gradient Boosting)
      âœ“ Study Suggester
      Question Bank: 80+ questions across 5 categories
   
   ğŸŒ Starting server on 0.0.0.0:7860
   ```

## API Endpoints

### POST /predict
Main prediction endpoint for all ML operations.

**Request:**
```json
{
  "command": "generate_quiz",
  "data": {
    "category": "algorithms",
    "difficulty": "medium",
    "career_path": "backend",
    "count": 5,
    "level": 10
  }
}
```

**Response:**
```json
{
  "success": true,
  "result": [...]
}
```

### GET /health
Health check endpoint.

## Connecting from Your App

Update your `.env` in Replit:
```
HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxx
USE_HUGGINGFACE=true
HF_MODEL_ENDPOINT=https://your-username-careerquest-ml-api.hf.space
```

## Logs Example

When the service receives requests, you'll see:
```
ğŸ”¬ Prediction Request | 2025-01-XX 01:30:45 PM
   Command: recommend_career
   âœ… Recommendation: backend
   Confidence: 85%
```
